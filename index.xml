<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nonbei alley on blog.salrashid.me</title>
    <link>https://blog.salrashid.me/</link>
    <description>Recent content in nonbei alley on blog.salrashid.me</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 10 May 2020 14:34:01 -0800</lastBuildDate>
    
	<atom:link href="https://blog.salrashid.me/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Firebase Storage and Authorization Rules engine &#39;helloworld&#39;</title>
      <link>https://blog.salrashid.me/posts/firebase_storage_rules/</link>
      <pubDate>Sun, 10 May 2020 14:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/firebase_storage_rules/</guid>
      <description>A couple days ago i finally started to tinker with firebase storage and its rules engine.
I did know about the rules engine for many years now and knew it was pretty flexible but never really noticed that it can use both request and resource attributes. What i mean by that is a firebase rule can evaluate and grant access at runtime using both something contained within the request (eg, id_token) and something about the target being accessed (eg a resource attribute).</description>
    </item>
    
    <item>
      <title>Docker mTLS ACLs with Open Policy Agent </title>
      <link>https://blog.salrashid.me/posts/docker_opa/</link>
      <pubDate>Fri, 10 Apr 2020 14:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/docker_opa/</guid>
      <description>Last week i was working with the docker daemon to help prepare it for remote cli access (which to be clear, isn&amp;rsquo;t a good idea but i&amp;rsquo;ll detail this anyway)
By default, the docker daemon runs locally and you use the docker cli to access the daemon which in turn does all the heavy lifting for you (as root usually, by the way!).
The docker daemon accepts requests from the cli as plain old REST api call which you can read about here under Develop with Docker Engine API.</description>
    </item>
    
    <item>
      <title>GPG Stream Encryption in golang by chaining Pipes</title>
      <link>https://blog.salrashid.me/posts/gpg_streams/</link>
      <pubDate>Fri, 21 Feb 2020 14:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/gpg_streams/</guid>
      <description>Sometime last year i wroteup a small article about how to use Cloud Run and Cloud Functions to encrypt data &amp;lsquo;on the fly&amp;rsquo;:
 GPG stream encryption and decryption on Google Cloud Functions and Cloud Run  In that article a source file in a Google Cloud Storage bucket is read in by a Cloud Function/Run, encrypted &amp;ldquo;on the fly&amp;rdquo; and saved in another GCS Bucket. All this happens in a way where the data is encrypted as a stream so as to minimize memory footprint.</description>
    </item>
    
    <item>
      <title>Importing SHA hashed password into Firebase and Identity Platform</title>
      <link>https://blog.salrashid.me/posts/firebase_salted_user_import/</link>
      <pubDate>Mon, 17 Feb 2020 14:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/firebase_salted_user_import/</guid>
      <description>or&amp;hellip;how i learned that firebase imports passwords as hash(salt+password)&amp;hellip;the really hard way.
Last week i assisted a customer in getting ready to import their existing users into Google Identity Platform. As is the case with many companies, their userbase&amp;rsquo;s identity store was your basic run of the mill salted password store. This is usually a no-brainer to migrate and the identity platform, firebase docs cover that ad nauseam (see Migrating users from an existing app</description>
    </item>
    
    <item>
      <title>Knative cli with Cloud Run (managed)</title>
      <link>https://blog.salrashid.me/posts/knative_cli_with_cloud_run/</link>
      <pubDate>Mon, 03 Feb 2020 14:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/knative_cli_with_cloud_run/</guid>
      <description>A very limited hack to use Knative CLI cli to do basic operations on Cloud Run (managed)
I was looking at the API calls yesterday to understand how GCP&amp;rsquo;s gcloud deploys and manages an app on Cloud Run. Cloud Run at the core used Knative so i figured &amp;ldquo;how hard is it to use knative&amp;rsquo;s on CLI to manage Cloud Run?&amp;rdquo;.
Well, you can to a limited degree and with some hacks.</description>
    </item>
    
    <item>
      <title>Redis with Envoy</title>
      <link>https://blog.salrashid.me/posts/redis_envoy/</link>
      <pubDate>Mon, 03 Feb 2020 14:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/redis_envoy/</guid>
      <description>Cheatsheet to setup Envoy to proxy Redis traffic using TLS and Redis AUTH.
I&amp;rsquo;m writing this up since i found it really tricky to setup the envoy side of things&amp;hellip;especially with both downstream and upstream AUTH:
hope this helps you spend some hours on other things..
What we&amp;rsquo;re going to do: Setup a go redis client app to talk via TLS to envoy. Envoy will then proxy requests to Redis server.</description>
    </item>
    
    <item>
      <title>Mounting CSEK protected disk with LUKS encryption on Google Compute Engine</title>
      <link>https://blog.salrashid.me/posts/gce_csek_luks/</link>
      <pubDate>Mon, 20 Jan 2020 01:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/gce_csek_luks/</guid>
      <description>Simple procedure that attaches a GCE persistent disk to a VM where the disk itself is encrypted by a key you define (Customer Supplied Encryption Key). In addition, the startup script also does a final round of encryption on top of that on the mounted disk using LUKS. Essentially, youâ€™re left with a disk that can only get decrypted if you have both encryption keys:
For example, the Disk is encrypted with CSEK:</description>
    </item>
    
    <item>
      <title>Knative Traffic Splitting</title>
      <link>https://blog.salrashid.me/posts/knative_traffic_splitting/</link>
      <pubDate>Wed, 08 Jan 2020 14:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/knative_traffic_splitting/</guid>
      <description>Sample getting started tutorial on how to do traffic splitting with Knative Serving using Istio.
This is just my &amp;ldquo;hello world&amp;rdquo; application demonstrating stuff here:
 Knative traffic-splitting Routing and managing traffic with blue/green deployment  While you can easily follow those tutorials, this article specifically designed to deconstruct the basic knative serving objects (Services, Congigurations, Routes, Revisions) and how to use them to split traffic.
  Note: GCP Cloud RUn does not yet suport tags</description>
    </item>
    
    <item>
      <title>Google Cloud KMS based Service Accounts for Authentication and SignedURLs</title>
      <link>https://blog.salrashid.me/posts/kms_service_accounts/</link>
      <pubDate>Mon, 06 Jan 2020 14:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/kms_service_accounts/</guid>
      <description>The following procedure details how to embed a Google Cloud KMS key as a Service Account.
There are two ways to associate a Service Account with a KMS key:
 Create a private key within KMS and then associate a Service Account with it. or Create a Service Account keypair; export the private key and import that key into KMS.  Once the Serivce Account private key is within KMS, you can do several things:</description>
    </item>
    
    <item>
      <title>Simple distributed tracing with OpenTracing and Stackdriver</title>
      <link>https://blog.salrashid.me/posts/opentelemetry_stackdriver/</link>
      <pubDate>Tue, 24 Dec 2019 14:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/opentelemetry_stackdriver/</guid>
      <description>Nothing much, just my variation/helloworld for opentelemetry in golang..its my variation of Opentelemetry-Distributed Tracing sample
This is a simple frontend-backend application you can run on your laptop which demonstrates distributed tracing between microservices.
What step 5 below shows is an inbound request to one microservice (/frontend) which emits some subspans, then makes an http call to a backend app (/backend) which also emits some spans. The final trace you see is a combined end-to-end trace between microservices.</description>
    </item>
    
    <item>
      <title>GCS SignedURL with Google AppEngine Standard (1st gen)</title>
      <link>https://blog.salrashid.me/posts/gae_signedurl/</link>
      <pubDate>Sun, 22 Dec 2019 14:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/gae_signedurl/</guid>
      <description>Over the years, I&amp;rsquo;ve repeatedly had to setup samples that use Google AppEngine&amp;rsquo;s (v1) to generate a SignedURL.
The following is nothing new but my variation of it (since i just had to do this again from scratch)
Sample code demonstrating GCS SignedURL using original-flavor Appengine (v1).
Note, if your&amp;rsquo;e reading this and your&amp;rsquo;e using Cloud Run, Cloud Functions or AppEngine v2, its much, much eaiser: just use the google-cloud-storage python library</description>
    </item>
    
    <item>
      <title>.NET on GCP</title>
      <link>https://blog.salrashid.me/posts/gcpdotnet/</link>
      <pubDate>Sun, 24 Apr 2016 14:34:01 -0800</pubDate>
      
      <guid>https://blog.salrashid.me/posts/gcpdotnet/</guid>
      <description>12/30/19: NOTE: as you can clearly tell, this article is dated. DO NOT use this (i&amp;rsquo;m leavig it up as a matter of record)
 Sample code demonstrating running trivial .NET web applications on Google Cloud Platform services.
These simply builds off of existing technologies and samples but configures it to run on GCP effeciently with healh checking and load balancing.
The example here uses Microsofts&amp;rsquo;s .NET Core 1.</description>
    </item>
    
  </channel>
</rss>